# C++ Project V

12112510李涵

# 1. 题目要求

BLAS（基本线性代数子程序）是提供执行基本向量和矩阵运算的标准构建模块的例程/函数。有三个级别的例程。广义矩阵乘法（GEMM）是BLAS库中最常用的函数之一。在BLAS库中，GEMM的定义为$C ← αAB + βC$，其中A和B是相同类型和相同大小的两个矩阵，α和β是两个标量。

请在C或C++中实现双精度矩阵的GEMM。请尽最大努力提高效率。

**要求：**

1. 函数的接口应与OpenBLAS库中的cblas_dgemm()一致，可以在以下文件中找到：https://github.com/xianyi/OpenBLAS/blob/develop/cblas.h。 调用cblas_dgemm()的示例可在此链接中找到：https://gist.github.com/xianyi/6930656。

2. 使用不同大小的矩阵对性能进行测试。您可以生成一些具有随机值的矩阵来测试您的函数。

3. 将您的实现与OpenBLAS中的cblas_dgemm()进行比较。您的实现结果应该与OpenBLAS的结果相同或非常相似。

4. 尝试提高您的实现速度，使其接近OpenBLAS的速度。

5. 在X86和ARM平台上测试您的程序，并描述它们之间的差异。

**测试环境：**

>CPU：AMD Ryzen 7 5800H（8核）    
>显卡：NVDIA GEFROCE RTX 3060 Laptop GPU 6GB  
>内存：16GB（3200MHz）  
>运行系统：Windows 10  
>C++编译器：mingw-GCC  
>C++版本：C++ 17.1.0    
>C++的IDE：Visual Studio Code 1.76.0  

# 2. cblas_dgemm()函数解读

下载安装参考：https://www.cnblogs.com/qujingtongxiao/p/10197784.html

函数原型如下：
```C
void cblas_dgemm(const enum CBLAS_ORDER Order,
                 const enum CBLAS_TRANSPOSE TransA,
                 const enum CBLAS_TRANSPOSE TransB,
                 blasint M, blasint N, blasint K,
                 double alpha,
                 const double *A, blasint lda,
                 const double *B, blasint ldb,
                 double beta,
                 double *C, blasint ldc);
```

其中各个参数的含义为：

* Order：矩阵的存储顺序，可以是行优先或者列优先。
* TransA 和 TransB：表示是否需要对A或B进行转置。
* M, N, K：描述矩阵A、B、C的维度。
* alpha 和 beta：计算中使用的标量值。
* A, B, C：存储矩阵数据的指针。
* lda, ldb, ldc：描述各个矩阵的前导维度（leading dimension）。

**Q:前导维度的作用和意义是什么？**
>A：
>
>前导维度是一个矩阵在内存中存储的方式的描述。具体来说，前导维度描述的是矩阵每行（对于行主序，row-major order）或每列（对于列主序，column-major order）的元素在内存中是如何存储的。
>
>在 C/C++ 中，数组默认是按行主序方式存储的，即一个二维数组中，每一行的元素都是连续存储的。这样，矩阵的前导维度就是矩阵的列数。前导维度的重要性在于，它允许程序以最有效的方式遍历矩阵的元素。
>
>对于按行主序存储的矩阵，通过在行内连续访问元素可以最大程度地利用 CPU 缓存，从而提高性能。同样，对于按列主序存储的矩阵，也是在列内连续访问元素。前导维度还允许我们在原始矩阵中有效地处理子矩阵，而不需要复制数据。例如，如果我们有一个大矩阵，我们可以只通过调整前导维度和起始指针就能处理这个大矩阵的一个子块。这可以在不牺牲性能的前提下提高代码的灵活性和可重用性。
>
>它能在宏定义帮我们大忙，比如行主序的index就能这样表示：
```C++
#define A(i, j) A[(i) * lda + (j)]
#define B(i, j) B[(i) * ldb + (j)]
#define C(i, j) C[(i) * ldc + (j)]
```

**Q：blasint是什么？为什么要设计这个东东？**
>A：
>
>这是一个抽象的整数类型，主要用于表示BLAS例程中的索引和大小参数。由于OpenBLAS需要在各种不同的平台上运行，所以blasint的具体实现可能会因平台和配置的不同而不同。
>
>blasint的主要目的是为了在处理大矩阵时提供足够的灵活性。在很多现代的系统上，一个int类型只能表示的最大整数是2的31次方减1。然而，大型科学和工程应用可能需要处理更大的矩阵，其中元素数量可能超过这个限制。为了解决这个问题，OpenBLAS的开发者可以配置blasint为一个可以表示更大整数的类型，例如long long或int64_t。这样，OpenBLAS就可以处理尺寸超过2的31次方的大矩阵。
>
>另一方面，对于一些较旧或资源受限的系统，使用32位整数可能更高效。在这些情况下，blasint可以被配置为int，以减少内存使用和提高性能。
>
>总的来说，blasint的设计使得OpenBLAS能够在不牺牲性能的情况下处理各种尺寸的矩阵，从而在各种不同的应用和平台上都能高效地工作。

# 3. 优化手段

为了测试不同大小的数据，并且与真实的GEMM方法比较。每次打印会有四个子模块。每一轮的矩阵均由`create_random_matrix()`，根据指定的尺寸创建。每一轮的两种测试均使用相同的矩阵。其中第一条为我自己的在当前尺寸下的运行时间，第二条是真实的在当前尺寸下的运行时间，第三条为两者的倍数上的差异（以便更清晰直观地认识到自己优化尚且不足。但要注意，因为真实的GEMM的运行效率极快，所以这个比值上的差异可能不完全准确）。测试数据分别为：$M = N = K = 200$, $M = N = K = 500$, $M = N = K = 1000$, $M = N = K = 2000$。所有数据均为在预热好编译器后（数据稳定后）测出的。

具体实现请查看`testGEMM.cpp`文件。

注：关于两个枚举类型以及`blasint`，为了测试方便（不用开两个文件来测试，或者避免写一堆分支语句来判断），以及它们的实现不是要点（前者十分简单，后者要涉及到对不同操作系统和平台的判断，比较繁琐），所以我就直接使用`blas.h`中的了。

PS：为了简便起见，在此测试的全都采用不翻转和行主序，故无具体判断和运算。

PPSS：参考了该教程的实现：https://github.com/flame/how-to-optimize-gemm/ and https://zhuanlan.zhihu.com/p/65436463

## 3.0 内存对齐

内存对齐后，可以避免跨越多个缓存行和浪费缓存行的存储空间，同时也能减少或避免缓存行冲突，从而提高并发访问的效率。

使用如下代码，为矩阵分配了一块按照16字节的边界进行对齐的对应大小的内存空间，同时如果分配失败会报错：
```C++
    if (posix_memalign((void**)&matrix, 16, M * N * sizeof(double)) != 0) {
        throw std::runtime_error("Failed to allocate aligned memory");
    }
```

## 3.1 基础实现

直接使用三层循环实现。

![PGH__2PB6__1__YOT2KV264.png](https://s2.loli.net/2023/05/21/zPy9oK2YUsnEkvS.png)

## 3.2 块分割 v1

本次优化采用了相对3.1来说更好的访问内存的顺序，对A、B和C的访问都是按照其存储顺序来进行的。对于A和C，我们按行访问；对于B，我们按列访问。这样可以更好地利用缓存，提高程序的性能。（详见`AddDot()`方法）

而在v1中，对C的访问是按行进行的，但对A和B的访问则不是。A被按行访问，而B被按列访问。由于处理器通常会缓存访问过的内存块，当我们跳到一个新的内存地址时，如果该地址未被缓存，那么就会产生一次缓存未命中（cache miss），需要从主内存中加载数据，这会导致较大的性能开销。

可以看到有所优化。尤其在尺寸较大后，相比于3.1的优化更为明显。

![_RM1W69X_F7R_O5P@5_LOZC.png](https://s2.loli.net/2023/05/21/eKVBt61bSGLN5AT.png)

## 3.3 块分割 v2

本次优化在3.2的基础上，采用了4次循环展开（即在内层循环中，对C的每个元素进行了4次更新。由于这四次操作是对相邻的内存位置进行的，因此在内存访问上也可以更好地利用缓存）。这相当于是运用了计组里面的pipline的知识，让更多指令能并发执行，从而更好地利用CPU资源。

发现优化效果几乎没有，原因是强大的C++编译器其实会自动进行有限度的循环展开了。。

![_CMCA_1O_G_SV___76VT_UK.png](https://s2.loli.net/2023/05/21/VPqSajokRnHpNhv.png)

## 3.4 循环合并 v1

本次优化在一个子方法体中，直接对C的四个元素进行更新。在这个过程中，几个独立的循环被合并为一个循环，在一个循环中完成多个操作。这样能减少循环的开销，并可能提高内存的局部性，从而提高缓存的利用效率。

另外，因为我在`AddDot4x1()`子方法体中，采取了和3.3同样的策略，即展开了循环体，处理器就更有可能隐式地对我的方法进行向量化和SIMD指令集优化。

可以看到这样的效率有了显著的提升。在尺寸较大时，效率提升甚至接近两倍。

<a href="https://sm.ms/image/XKeRLFnT3AGoctv" target="_blank"><img src="https://s2.loli.net/2023/05/22/XKeRLFnT3AGoctv.png" ></a>

## 3.5 寄存器优化 v1

在本次优化中，相对于3.4而言，加入了寄存器变量（注：在C++17及以后的标准中，寄存器的`register`关键词不用再显示调用了，编译器会自己做出是否要使用的决定），将要反复用到的几个变量存入了其中（分别为`c_00_reg`、`c_01_reg`、`c_02_reg`、`c_03_reg`、`a_0p_reg`）（详见`regAddDot4x1()`方法）。

这样，我们在循环结束后只需要将寄存器中的值写回到内存，减少了内存的访问。而相比于主存（或缓存），寄存器的访问速度更快。

可以看到效率还是有了一定的提升。尤其是在尺寸较小时，提升更为明显。（因为根据数据局部性原理，当尺寸较小时，需要的数据更有可能被反复利用，缓存命中率更大，效率自然也就更高）。

<a href="https://sm.ms/image/tS1Acy2Iza9XesU" target="_blank"><img src="https://s2.loli.net/2023/05/22/tS1Acy2Iza9XesU.png" ></a>

## 3.6 指针访问优化 v1 && 循环展开 v2 && 间接引址 v1

本次优化，相对于3.5，新增了以下内容（详见`ptrRegAddDot4x1()`方法）。

1. 引入了指针访问（将`B( p, 0 )`更改为使用`bp0_ptr`来访问具体元素）。这样减少了在循环中的内存访问次数和索引计算量，提高了代码的执行效率。同时，通过指针递增访问元素，也更好地利用了数据局部性，可能使得被访问的数据更有可能在缓存中，从而提高缓存命中率，进一步提高代码执行效率。最关键的是，这样我们就能通过一个加法，避免了计算idx时的乘法运算。在计组中我们学过，乘法运算非常消耗时间，时间复杂度很高。

2. 另外还将循环展开（具体表现为让 `k += 4`），具体原理见3.3。

3. 本来在3.6.1中，是采用`ptr++`的操作来进行迭代的，但应该注意到，使用`ptr++`后，还需要在这个新的地址值存回内存中（或者缓存中），这又会造成额外的读写开销。而且对指针的操作（例如递增）通常需要一些时间，在一些处理器架构中，这些操作可能会导致流水线停顿，降低了代码的性能。为了解决这一问题，使用了间接引址（中间更改为`ptr + 1`，循环结束后一次性加4并保存）。

综合来看，还是起到了挺不错的优化效果的。

<a href="https://sm.ms/image/6ehYpdmBrzg8oSQ" target="_blank"><img src="https://s2.loli.net/2023/05/22/6ehYpdmBrzg8oSQ.png" ></a>

## 3.7 块分割 v3

现在为了更好地有效地利用矢量指令和矢量寄存器，我们将由最开始的一次性计算一个元素或者1x4的四个元素，到一次性计算一个4x4的矩阵块的十六个元素（详见`AddDot4x4()`方法）。

现在这样可以更加有效地减少对内存的访问次数。对于高性能计算，内存访问往往是性能瓶颈，因此减少内存访问可以带来显著的性能提升。（其余的使用寄存器，指针访问优化和循环展开都同上，便不再赘述了）。

从结果来看，效率还是有了些微的提升。

<a href="https://sm.ms/image/oSQBDp4qeEXv6nY" target="_blank"><img src="https://s2.loli.net/2023/05/22/oSQBDp4qeEXv6nY.png" ></a>

## 3.8 寄存器优化 v2

本次优化采用的是SIMD寄存器（也被称为矢量化寄存器或者向量寄存器），它的定义如下：
```C++
typedef union
{
  __m128d v;
  double d[2];
} v2df_t;
```

* \__m128d v：这是一个SSE（Streaming SIMD Extensions）数据类型，代表一个包含两个双精度浮点数的128位向量。这个成员被用于SSE向量化操作，能够同时对两个双精度浮点数进行处理，如加法、乘法等，从而提高计算效率。

* double d[2]：这是一个包含两个双精度浮点数的数组。在一些情况下，程序可能需要分别访问或操作向量中的每个元素，而不是将它们作为一个向量处理。此

通过这样的设计，在进行4x4矩阵乘法时，我们能同时计算两行（由于使用了128位寄存器，每次可以处理两个64位浮点数）。因此，比如说，`c_00_c_10_vreg`中存储的是两个结果元素`C(0,0)`和`C(1,0)`，这两个元素来自结果矩阵的连续两行。在执行完所有的矩阵乘法运算后，将会把结果累加到矩阵C中相应的位置。这样我们就利用了SIMD并行计算能力，可以同时处理两个数据，提高了计算的效率。

同时还有以下几点需要注意的：

* 在分配内存空间时，应该让首地址值保证是16字节对齐的，这个在前面创建内存的3.0部分就已经做到了。~~（BUT：很奇怪的地方。。即便我这样做了依然在p为奇数时报segmentation fault。。。反复修理后都没有用，最后只能选择使用`_mm_loadu_pd`来加载（它能处理好未对齐的内存空间，尽管这样效率会降低））。~~ 额。。最后发现，是我没有分清楚行主序和列主序。。加上没了解到`_mm_load_pd`一次性会读取16字节的数据，也就是一次性读取两个double类型的数据。。最后还是修好了！
* 为了启用SSE3指令，需要在CMakeLists里面添加新的编译选项`-msse3`。~

可以看到效率正在龟速地提升。。

<a href="https://sm.ms/image/Sd4BR1PcJtzD3Ou" target="_blank"><img src="https://s2.loli.net/2023/05/22/Sd4BR1PcJtzD3Ou.png" ></a>

## 3.9 块分割 v4

在本次优化中，我们继续对矩阵乘法的块细化，分割地更彻底（因为上面的做法有缺陷，如果矩阵尺寸超过了cache的大小，cache的miss率就会逐步提升，性能也会随之下滑）。我们设置两个常量（具体的合理数值是根据我的硬件系统，即L2 cache的大小测出来的。。）：
```C++
#define mc 512
#define kc 256
```
然后在最大的循环中，每次对大小为`mc * n`的C矩阵的一部分操作。

正常来说，将大型的矩阵分成分为小块，可以让这些小块能够适应 CPU 的缓存大小，减少缓存未命中，从而提高性能。所以从理论上分析，本次优化应该对大尺寸（$M = N = K = 2000$这样的矩阵）有着比较明显的功效。但实际数据显示，这样的优化效果几乎没有。。我也不清楚为什么。。（明明之前的块分割都是有明显效果的）。

<a href="https://sm.ms/image/IlnufctWx26rNFp" target="_blank"><img src="https://s2.loli.net/2023/05/22/IlnufctWx26rNFp.png" ></a>

## 3.10 数据打包 v1

**数据打包：** 将数据按照一定规则或格式进行组织和存储的过程。它通常用于在计算机系统中将多个数据项或数据结构组合成更大的单元，以便于传输、存储或处理。

相较于3.9的优化，新增了`PackMatrixB()`这个操作。它的作用是将B矩阵的一部分转化为连续的内存，以便后续使用。该函数将一个kx4的子块从B矩阵中取出，并将这些元素存储到一个连续的数组`packageB`中。

在处理数据时，CPU 的效率往往取决于数据在内存中的布局。具体来说，如果数据在内存中是连续存储的，那么 CPU 就可以高效地一次性从内存中读取多个数据（此时矩阵已经预热好，存放到cache里面了）。反之，如果数据在内存中是离散存储的，那么 CPU 就需要多次访问内存，这会显著降低处理速度。如此这般操作后，在`pacVecAddDot4x4()`函数中，就可以使用如下的代码来操作：
```C++
  const double* b_p0_b_p1_ptr = &B( 0, 0 );

  for (int p = 0; p < K; p++){
    b_p0_b_p1_vreg.v = _mm_load_pd( (double *) b_p0_b_p1_ptr );
    b_p2_b_p3_vreg.v = _mm_load_pd( (double *) b_p0_b_p1_ptr + 2 );
    b_p0_b_p1_ptr += 4;
  }
```
这样就可以直接使用指针来进行操作，避免对index的计算。

并且为了减少不必要的计算和内存访问（减少不必要的打包次数），在`smallBlockWithPackage()`函数中，还添加了一个`if(j == 0)`的判断。使得它只会被打包一次（因为反正矩阵B的元素不会有任何改变）。

最终结果如下，优化效率仍在龟速前行。（为什么网上说这样的优化，对于较大的矩阵效率提升能达到50%？）

<a href="https://sm.ms/image/QrTUZ52qYHwBADb" target="_blank"><img src="https://s2.loli.net/2023/05/22/QrTUZ52qYHwBADb.png" ></a>

## 3.11 数据打包 v2

本次优化在3.10的基础上，又加上了对矩阵A的数据打包。通过`PackMatrixA()`方法，使得打包后的矩阵A成为了列主序的存储方式。然后我们就可以这样遍历矩阵A：
```C++
 const double* a_0p_ptr = &A( 0, 0 );
 for (int p = 0; p < K; p++){
    a_0p_vreg.v = _mm_loaddup_pd( (double *) a_0p_ptr );  
    a_1p_vreg.v = _mm_loaddup_pd( (double *) a_0p_ptr + 1 );   
    a_2p_vreg.v = _mm_loaddup_pd( (double *) a_0p_ptr + 2 );   
    a_3p_vreg.v = _mm_loaddup_pd( (double *) a_0p_ptr + 3 );
    a_0p_ptr += 4;  
 }    
```

同样的，这样就可以直接使用指针来进行操作，避免对index的计算。

    优化效率聊胜于无。。估计是因为其本身就是流式访存了（但发现这几次的优化都是集中体现在size较大的矩阵上，推测是因为）

<a href="https://sm.ms/image/pTk3o8hxYIvqmrc" target="_blank"><img src="https://s2.loli.net/2023/05/22/pTk3o8hxYIvqmrc.png" ></a>

# 3.12 关于openMP

在此之前尝试了一下`OpenMP`的`#pragma omp parallel for`的并行化处理，但是效果微乎其微。。？~~盲猜又是编译器自动帮我并行化一部分了，所以就不引入了~~

网上查到一种说法：在执行gemm操作时，通常是计算能力，而不是内存带宽或其他资源，成为限制性能的主要因素。换言之，我的处理器在执行这样的操作时可能会达到其最大的计算能力。在某些特定的操作，比如gemm算子，一个核心在执行时已经充分利用了计算资源，那么同一核心的多线程可能就不会带来额外的性能提升。（这肯定只是部分原因，因为好歹我的电脑有8核呢。。）

另外的猜想是产生了内存访问竞争（如果多个线程在访问相同的内存位置，可能会引起“缓存抖动”或者其他内存访问问题，导致性能下降），因为我相当于要不停地访问A和B矩阵的若干个相同的元素。

综上而言，本次project就不显示地使用并行化优化了。

## 3.13 启动编译优化！

接下来便是大杀器了，直接开启多个编译优化！分别为`-O3`，`-march=native`，`-funroll-loops`，`-ffast-math`

* -O3：这是GCC编译器的一个优化等级选项。它尝试提供最大程度的优化，包括内联函数、移除循环冗余计算、循环展开、向量化等。这可能会导致编译时间增加和程序大小增大。此外，这种级别的优化有时可能会影响调试和代码理解。

* -march=native：这个选项告诉编译器生成针对当前机器类型的优化代码。这里的"native"意味着编译器会尝试识别运行编译命令的机器的硬件特性，并优化代码以利用这些特性。这可能包括特定的指令集扩展，如SSE，AVX，或者其他硬件特性。

* -funroll-loops：这个选项告诉编译器尝试循环展开。循环展开是一种优化技术，它可以减少循环的迭代次数，通过将循环体复制多次来实现。这可以减少循环控制语句（例如增量和条件跳转）的开销，但会增加代码大小。

* -ffast-math：这个选项告诉编译器放宽一些对于浮点数学运算的精度和标准的要求，以获得更快的运行速度。这可能包括对一些数学函数的近似计算，忽视某些NaN（非数字）和Inf（无穷）的情况，以及一些其他的算术优化。

结果如下，可以看到效率飞增，对于较大的矩阵，效率提升了五六倍。甚至对于尺寸较小的矩阵，已经超过了真实的gemm的效率！（估计是因为我目前没有做过多的检查）

<a href="https://sm.ms/image/a9AxTq4YO1GzBoQ" target="_blank"><img src="https://s2.loli.net/2023/05/24/a9AxTq4YO1GzBoQ.png" ></a>

## 3.14 另外一些可能的优化。。

根据网上教程来看，OpenBLAS的GEMM的优化还不止这些。但如果想要再度提升，有两个方向可以选择：

1. 深入硬件，瞄准汇编：可能需要进行如内嵌汇编（将汇编代码直接嵌入到C或C++代码中），重排流水线（通过重新排列代码，使得处理器可以在等待一条指令完成的同时开始执行下一条指令）和更加深入地利用（榨干）硬件设备的资源（要求对具体的硬件设备极度了解），但这些过于复杂，所以我选择战略性放弃了。。

2. 切换目标，看向GPU：另外，其实也可以借助GPU的**CUDA**来做优化，但考虑到咱的gemm应该是要面向CPU用户的（加上时间关系），就暂时只作为未来优化目标了。在这放出一个**CUDA**优化的官方参考链接：https://docs.nvidia.com/cuda/cublas/ 。（然后其实，GPU的优化思路和CPU的基本一致，无非就是将经常访问的数据尽量放到寄存器中，对数据进行分块，对数据预处理预加载等。）

## 3.15 关于2的幂次方

在测试中，注意到了一个现象:
<a href="https://sm.ms/image/UZiy5Rg6tx3ovhk" target="_blank"><img src="https://s2.loli.net/2023/05/24/UZiy5Rg6tx3ovhk.png" ></a>

可以看到，当尺寸为2的幂次方时，它的时间会大幅度增长。我的推测是，如果矩阵的行或列数是缓存行大小的倍数，那么连续的矩阵行或列可能会映射到同一个缓存行中。因此，在计算过程中，需要频繁地访问不同的缓存行，从而导致频繁的缓存未命中，进一步导致性能下降。

<span style="color:red;">奇怪的是，后来当我再测试的时候，这种现象却消失了。。令人费解。。</span>

# 4.完备性 && 鲁棒性

本环节会优化`own_dgemm()`（以及所有派生的最终优化的方法）接口，使得它具有良好的鲁棒性和完备性。

具体实现可以参考`finalGEMM.cpp`文件。

PS：对于之前的宏定义:
```C++
#define A(i, j) A[(i) * lda + (j)]
#define B(i, j) B[(i) * ldb + (j)]
#define C(i, j) C[(i) * ldc + (j)]
```
因为行主序和列主序的存储顺序不同，所以如果要改为列主序的话，就需要在头文件中重新定义为：
```C++
#define A(i, j) A[(j) * lda + (i)]
#define B(i, j) B[(j) * ldb + (i)]
#define C(i, j) C[(j) * ldc + (i)]
```

## 4.1 数据检查

在进入到方法`own_dgemm()`时，会进行一系列检查：

1. 对传进来的三个指针，使用`check_nullptr()`方法进行检查。若小于等于0，则会抛出对应的异常。
2. 对各个`blasint`使用`check_size()`进行检查。若小于等于0，则会抛出对应的异常。

在矩阵转置方法`transMatrix()`中，会先对尺寸进行一系列检查：
1. 在对行数列数转置后（如果需要的话），如果A矩阵的列数不等于B矩阵的行数，无法相乘直接返回
2. 在对行数列数转置后（如果需要的话），如果A矩阵的行数不等于M矩阵的行数，或者B矩阵的列数不等于N矩阵的列数，无法相加直接返回

在各个需要创建新矩阵的函数内，也会检查是否分配成功。如果内存不足导致分配失败了，也会抛出异常并返回。

## 4.2 增加对列主序的支持

**列主序：** 多维数组或矩阵的元素按列进行存储。也就是说，对于一个二维数组，它的列被依次存储在内存中，而每一列的元素则按行顺序排列。

前面的优化代码全都默认存储方式为行主序，在此增加对列主序的支持。也就是说，在每个子方法体的参数列表里面引入对主序的判断。（然后其实把A和B矩阵的操作彻底颠倒换过来就可以了）

## 4.3 对矩阵转置的支持

一种想法是，通过对**指针的引用变换**和对**前导维度**的利用，完成名义上的矩阵转置。这是实际的OpenBLAS的GEMM的做法。

而另一种思路是，在做实际的矩阵乘法前，直接将该矩阵做实际意义上的转置。虽然这样会耗费一些内存空间和提高时间复杂度，但是这样比较直观明了（我是真的推不懂在不做实际矩阵转置情况下，如何进行打包和分块等问题呜呜呜），而且提高的时间复杂度相较整体而言也比较小。所以本次项目就采用这个了。（PS：由于共轭转置要牵涉到对复数运算的支持，比较复杂，本次项目先暂不讨论）。



在此简单推导一下变换后的坐标，给出一个简单的4X3矩阵（假设为行主序，则有$M = 4, K = 3, lda = 3$）：

1 2 3 4

5 6 7 8

9 1 2 3

其转置后变成了如下的3×4矩阵：

1 5 9

2 6 1

3 7 2

4 8 3

现在矩阵的要往右遍历，只需：next_ptr = cur_ptr + M;

当矩阵遍历完一行，要到下一行时，只需：next_ptr = cur_ptr + 1;


因为对于单独的矩阵转置的优化的思路也和前面的类似了，本次项目就只实现了一个最初级的版本（如有兴趣，可参阅：https://blog.csdn.net/yan31415/article/details/107876678 ）

详细操作请参见`transMatrix()`方法

## 4.4 对常规数据的支持

因为我都是以4×4的单元对数据集中进行处理，这就会导致当尺寸不是4的倍数时发生内存溢出/越界。所以这就用到了第三次项目中，学到的卷积神经网络的**填充（padding）** 操作。通过新建一块大小为 $[(M / 4 + 1) * 4] * [(N / 4 + 1) * 4]$的内存空间，然后将原先的矩阵的数值拷贝进来即可。（尝试过直接在原先的内存空间上操作，但显然不行。。因为你无法确保原先这块内存空间的外部会不会有其他的也已经分配的内存空间。。）

详细操作请参见`expandMatrix()`方法

## 4.5 内存释放

在`transMatrix()`和`expandMatrix()`等一系列方法中，我们不得不为新的矩阵开辟了一块新的内存空间区域。为了避免内存泄漏（会导致程序的内存占用不断增加，最终耗尽系统可用内存，使程序崩溃或者变得异常缓慢），都会及时地在后面通过`free()`将不用的内存空间释放掉。

另外为了能成功释放，需要用一个非`const`的指针指向原始的内存首地址值，然后还要用`const_cast<double*>`进行一个强制类型转换。

## 4.6 测试

接下来会用五花八门的矩阵和条件对代码进行测试。同时会用官方的cblas库的gemm验证正确性。相关数据和条件都已经罗列在图片中了。

为了避免一些极为精细的误差所导致的检测错误，我不再判断两个值是否相等，而是：
```C++
const double MAX_INTERVE = 1e-6;
if(C[i] - C2[i] > MAX_INTERVE || C[i] - C2[i] < -MAX_INTERVE){
    std::cout << "error happen!" << std::endl;}
```


### 4.6.1 正常矩阵乘法

<a href="https://sm.ms/image/mjIds29qgYeoiTf" target="_blank"><img src="https://s2.loli.net/2023/05/25/mjIds29qgYeoiTf.png" ></a>

### 4.6.2 列主序的矩阵乘法

<a href="https://sm.ms/image/YnNajGq7CkgHUzS" target="_blank"><img src="https://s2.loli.net/2023/05/25/YnNajGq7CkgHUzS.png" ></a>

### 4.6.3 列主序且包含矩阵转置的矩阵乘法

<a href="https://sm.ms/image/UIhVNaGuHoZ1WCP" target="_blank"><img src="https://s2.loli.net/2023/05/25/UIhVNaGuHoZ1WCP.png" ></a>

### 4.6.4 列主序并且包含两个矩阵转置的矩阵乘法

<a href="https://sm.ms/image/eaMizZAF2N3pLPk" target="_blank"><img src="https://s2.loli.net/2023/05/26/eaMizZAF2N3pLPk.png" ></a>

### 4.6.5 行主序并且列数和行数都不为4的整数倍的矩阵乘法

<a href="https://sm.ms/image/zfhJl97bu1STqUi" target="_blank"><img src="https://s2.loli.net/2023/05/26/zfhJl97bu1STqUi.png" ></a>

### 4.6.6 列主序并且列数和行数都不为4的整数倍的包含两个矩阵转置的矩阵乘法

<a href="https://sm.ms/image/9HohdOglSXm7QiG" target="_blank"><img src="https://s2.loli.net/2023/05/26/9HohdOglSXm7QiG.png" ></a>

# 5. 总结

又是一次收益颇丰的项目。通过对OpenBLAS的dgemm的架构和核心思想的学习，我深刻地了解认识了优化矩阵乘法运算的方法，可以总结为以下几条：

1. 基于缓存的优化：OpenBLAS利用CPU缓存的特性进行优化。它将矩阵分块处理，以使得每个块的数据可以适应CPU缓存的大小，并尽量减少数据的访问次数。这样可以提高数据的局部性，减少缓存未命中的情况，从而提高计算效率。

2. 矩阵乘法的分解：OpenBLAS使用了块分解，将原始的矩阵乘法分解为多个子问题的乘法运算。这样可以有效地利用CPU的并行性，将计算任务分发到多个计算单元上同时进行计算，从而加速运算过程。

3. 寄存器优化：OpenBLAS利用寄存器的高速存取特性进行优化。它会将一些常用的数据加载到寄存器中，并通过寄存器级别的操作来进行计算，减少内存的访问次数，提高计算效率。

4. SIMD指令优化：OpenBLAS利用向量化指令（如SSE、AVX等）进行优化。它将多个数据元素打包成一个向量，并利用SIMD指令进行并行计算，从而提高计算吞吐量
